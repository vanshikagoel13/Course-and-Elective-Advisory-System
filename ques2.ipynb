{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "import scipy.linalg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given initial point\n",
    "a,b = 1,1\n",
    "X = np.array([1,1])\n",
    "# defining the given function f(x)\n",
    "def f(X):\n",
    "    return ((X[0]**2 - 3*X[1]**2)**2 + (math.sin(X[0]**2 + X[1]**2))**2)\n",
    "\n",
    "# defining the derivatives and hessian matrix for the given function\n",
    "def d11(X):\n",
    "    return 8*(X[0]**2)*math.cos(2*(X[0]**2) + 2*(X[1]**2)) + 12*(X[0]**2) - 12*(X[1]**2) + 2*math.sin(2*(X[0]**2) + 2*(X[1]**2))\n",
    " \n",
    "def d12(X):\n",
    "    return 8*X[0]*X[1]*(math.cos(2*(X[0]**2) + 2*(X[1]**2))-3)\n",
    "\n",
    "def d22(X):\n",
    "    return -12*(X[0]**2) + 8*(X[1]**2)*math.cos(2*(X[0]**2) + 2*(X[1]**2)) + 108*(X[1]**2) + 2*math.sin(2*(X[0]**2) + 2*(X[1]**2))\n",
    "\n",
    "def dx(X):\n",
    "    return 4*X[0]*((X[0]**2) - 3*(X[1]**2)) + 2*X[0]*math.sin(2*(X[0]**2) + 2*(X[1]**2))\n",
    "\n",
    "def dy(X):\n",
    "    return -12*X[1]*(X[0]**2 - 3*X[1]**2) + 4*X[1]*math.sin(X[0]**2+X[1]**2)*math.cos(X[0]**2+X[1]**2)\n",
    "\n",
    "# stopping criterion\n",
    "stop = 10^-6\n",
    "\n",
    "# defining the line search subroutine\n",
    "def line_search(d,X,D):\n",
    "    alpha = 0.2\n",
    "    t = 1\n",
    "    beta = 0.7\n",
    "    while (f(X) - f(np.add(X,t*d)) < alpha*t*(np.dot(D,d))):\n",
    "        t = beta*t\n",
    "    return t\n",
    "\n",
    "\n",
    "# gradient of the initial point\n",
    "grad = np.array([dx(X), dy(X)])\n",
    "gradnorm = np.linalg.norm(grad)\n",
    "\n",
    "while gradnorm > stop:\n",
    "    hessianM = np.array([[d11(X), d12(X)],[d12(X), d22(X)]])\n",
    "\n",
    "    # calculating the eignevalues of hessian matrix\n",
    "    eval, evec = scipy.linalg.eig(hessianM)\n",
    "\n",
    "    # if all eigenvalues are positive then positive definite and use newton else use gradient descent\n",
    "    if(all(k > 0 for k in eval)):\n",
    "        d = np.matmul(np.linalg.inv(hessianM),np.negative(grad))\n",
    "    else:\n",
    "        d = np.negative(grad)\n",
    "\n",
    "    D = np.negative(np.array([dx(X), dy(X)]))\n",
    "    t = line_search(d,X,D)\n",
    "\n",
    "    # updating X\n",
    "    X = X + t*d\n",
    "\n",
    "    # updating gradient of function for new value of X\n",
    "    grad = np.array([dx(X), dy(X)])\n",
    "    gradnorm = np.linalg.norm(grad)\n",
    "\n",
    "\n",
    "print(\"computed unconstrained minimum is: - \")\n",
    "print(X)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
